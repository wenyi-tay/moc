{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1815b9e2",
   "metadata": {},
   "source": [
    "# To put all summaries into the same json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "256e831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "99a0793a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## put in the directory of the project\n",
    "proj_dir = \"/Users/wenyitay/Documents/moc/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0db32f",
   "metadata": {},
   "source": [
    "## Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "35d3d293",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read fewsum\n",
    "\n",
    "## extract it and output as a list of dictionaries.\n",
    "## each item in the list is a summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5474c75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917bfaeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56bd73e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b75c4f4e",
   "metadata": {},
   "source": [
    "## Yelp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97344449",
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract it and output as a list of dictionaries.\n",
    "## each item in the list is a summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d9451f",
   "metadata": {},
   "source": [
    "## Bertcent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fe88c4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "## read file\n",
    "df = pd.read_csv(proj_dir + 'data/raw annotations/yelp/yelp100_bertcent_annotated.csv')\n",
    "\n",
    "## create a list of hold each dictionary\n",
    "ls_temp = []\n",
    "\n",
    "## extract the info I want\n",
    "for index, row in df.iterrows():\n",
    "    dict_temp = {\n",
    "        \"id\" : row[\"id\"],\n",
    "        \"system\" : \"bertcent\",\n",
    "        \"summary_text\" : row[\"summary\"],\n",
    "        \"conflict_label\" : row[\"not consistent\"]\n",
    "    }\n",
    "    ls_temp.append(dict_temp)\n",
    "    \n",
    "## export the file\n",
    "with open(proj_dir + \"data/yelp100_bertcent_annotated.json\",\"w\") as final:\n",
    "    json.dump(ls_temp, final) \n",
    "\n",
    "print(len(ls_temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7198282",
   "metadata": {},
   "source": [
    "### Copycat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0f58f9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "## read file\n",
    "df = pd.read_csv(proj_dir + 'data/raw annotations/yelp/yelp100_copycat_annotated.csv')\n",
    "\n",
    "## create a list of hold each dictionary\n",
    "ls_temp = []\n",
    "\n",
    "## extract the info I want\n",
    "for index, row in df.iterrows():\n",
    "    dict_temp = {\n",
    "        \"id\" : row[\"id\"],\n",
    "        \"system\" : \"copycat\",\n",
    "        \"summary_text\" : row[\"copycat\"],\n",
    "        \"conflict_label\" : row[\"not consistent\"]\n",
    "    }\n",
    "    ls_temp.append(dict_temp)\n",
    "    \n",
    "## export the file\n",
    "with open(proj_dir + \"data/yelp100_copycat_annotated.json\",\"w\") as final:\n",
    "    json.dump(ls_temp, final)  \n",
    "\n",
    "print(len(ls_temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f4f4de",
   "metadata": {},
   "source": [
    "### Denoisesum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "63a8964b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "## read file\n",
    "df = pd.read_csv(proj_dir + 'data/raw annotations/yelp/yelp100_denoisesum_annotated.csv')\n",
    "\n",
    "## create a list of hold each dictionary\n",
    "ls_temp = []\n",
    "\n",
    "## extract the info I want\n",
    "for index, row in df.iterrows():\n",
    "    dict_temp = {\n",
    "        \"id\" : row[\"Input.business_id\"],\n",
    "        \"system\" : \"denoisesum\",\n",
    "        \"summary_text\" : row[\"summary\"],\n",
    "        \"conflict_label\" : row[\"not consistent\"]\n",
    "    }\n",
    "    ls_temp.append(dict_temp)\n",
    "    \n",
    "## export the file\n",
    "with open(proj_dir + \"data/yelp100_denoisesum_annotated.json\",\"w\") as final:\n",
    "    json.dump(ls_temp, final) \n",
    "\n",
    "print(len(ls_temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45315061",
   "metadata": {},
   "source": [
    "### Meansum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c805647c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "## read file\n",
    "df = pd.read_csv(proj_dir + 'data/raw annotations/yelp/yelp100_meansum_annotated.csv')\n",
    "\n",
    "## create a list of hold each dictionary\n",
    "ls_temp = []\n",
    "\n",
    "## extract the info I want\n",
    "for index, row in df.iterrows():\n",
    "    dict_temp = {\n",
    "        \"id\" : row[\"Input.business_id\"],\n",
    "        \"system\" : \"meansum\",\n",
    "        \"summary_text\" : row[\"summary\"],\n",
    "        \"conflict_label\" : row[\"not consistent\"]\n",
    "    }\n",
    "    ls_temp.append(dict_temp)\n",
    "    \n",
    "## export the file\n",
    "with open(proj_dir + \"data/yelp100_meansum_annotated.json\",\"w\") as final:\n",
    "    json.dump(ls_temp, final)  \n",
    "\n",
    "print(len(ls_temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2c8d5f",
   "metadata": {},
   "source": [
    "### Opiniondigest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f1d7c3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n"
     ]
    }
   ],
   "source": [
    "## read file\n",
    "df = pd.read_csv(proj_dir + 'data/raw annotations/yelp/yelp100_opiniondigest_annotated.csv')\n",
    "\n",
    "## create a list of hold each dictionary\n",
    "ls_temp = []\n",
    "\n",
    "## extract the info I want\n",
    "for index, row in df.iterrows():\n",
    "    dict_temp = {\n",
    "        \"id\" : row[\"eid\"],\n",
    "        \"system\" : \"opiniondigest\",\n",
    "        \"summary_text\" : row[\"pred\"],\n",
    "        \"conflict_label\" : row[\"not consistent\"]\n",
    "    }\n",
    "    ls_temp.append(dict_temp)\n",
    "    \n",
    "## export the file\n",
    "with open(proj_dir + \"data/yelp100_opiniondigest_annotated.json\",\"w\") as final:\n",
    "    json.dump(ls_temp, final)  \n",
    "\n",
    "print(len(ls_temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53522b2",
   "metadata": {},
   "source": [
    "### Plansum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2dcad89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "## read file\n",
    "df = pd.read_csv(proj_dir + 'data/raw annotations/yelp/yelp100_plansum_annotated.csv')\n",
    "\n",
    "## create a list of hold each dictionary\n",
    "ls_temp = []\n",
    "\n",
    "## extract the info I want\n",
    "for index, row in df.iterrows():\n",
    "    dict_temp = {\n",
    "        \"id\" : row[\"id\"],\n",
    "        \"system\" : \"plansum\",\n",
    "        \"summary_text\" : row[\"summary\"],\n",
    "        \"conflict_label\" : row[\"not consistent\"]\n",
    "    }\n",
    "    ls_temp.append(dict_temp)\n",
    "    \n",
    "## export the file\n",
    "with open(proj_dir + \"data/yelp100_plansum_annotated.json\",\"w\") as final:\n",
    "    json.dump(ls_temp, final)  \n",
    "\n",
    "print(len(ls_temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc99ebc9",
   "metadata": {},
   "source": [
    "### QT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4ae0c398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         prod_id                                            summary  \\\n",
      "0   dev_entity-0  Side of cucumber sauce. Babaganoush and the wa...   \n",
      "1   dev_entity-1  Very unique. Very good! Food very good. Everyt...   \n",
      "2  dev_entity-10  Due to their ignorance I won't be shopping the...   \n",
      "3  dev_entity-11  The food is incredible, the mood is nice and q...   \n",
      "4  dev_entity-12  It's perfectly fine. Losing another customer T...   \n",
      "\n",
      "   not consistent  within_same_sentence  adj_sentence  across_sentences  \n",
      "0             NaN                   NaN           NaN               NaN  \n",
      "1             NaN                   NaN           NaN               NaN  \n",
      "2             NaN                   NaN           NaN               NaN  \n",
      "3             NaN                   NaN           NaN               NaN  \n",
      "4             NaN                   NaN           NaN               NaN  \n",
      "200\n"
     ]
    }
   ],
   "source": [
    "## read file\n",
    "df = pd.read_csv(proj_dir + 'data/raw annotations/yelp/yelp100_qt_annotated.csv')\n",
    "print(df.head())\n",
    "## create a list of hold each dictionary\n",
    "ls_temp = []\n",
    "\n",
    "## extract the info I want\n",
    "for index, row in df.iterrows():\n",
    "    dict_temp = {\n",
    "        \"id\" : row[\"prod_id\"],\n",
    "        \"system\" : \"qt\",\n",
    "        \"summary_text\" : row[\"summary\"],\n",
    "        \"conflict_label\" : row[\"not consistent\"]\n",
    "    }\n",
    "    ls_temp.append(dict_temp)\n",
    "    \n",
    "## export the file\n",
    "with open(proj_dir + \"data/yelp100_qt_annotated.json\",\"w\") as final:\n",
    "    json.dump(ls_temp, final)  \n",
    "\n",
    "print(len(ls_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3058dc01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ba986e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ba16294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7aOaX7QASqa8ab8eAx8TEA\n",
      "4HoCAPiFH2BFznYxGR7sjQ\n",
      "5ts_r4K6y103zNXt0k6nEg\n"
     ]
    }
   ],
   "source": [
    "# Opening JSON file\n",
    "f = open('mydata.json')\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    " \n",
    "# Iterating through the json\n",
    "# list\n",
    "for i in data:\n",
    "    print(i[\"id\"])\n",
    "\n",
    "# Closing file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "49ebf791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '7aOaX7QASqa8ab8eAx8TEA',\n",
       "  'system': 'denoisesum',\n",
       "  'summary_text': \"love everything about this place . the staff is friendly and friendly . the food is good , staff is very friendly . i can ' t get enough of any other than that , but i won ' t be disappointed . i will definitely come back .\",\n",
       "  'conflict_label': 0},\n",
       " {'id': '4HoCAPiFH2BFznYxGR7sjQ',\n",
       "  'system': 'denoisesum',\n",
       "  'summary_text': \"this is a great family owned business . the service is fantastic , fast , and friendly . i didn ' t know if i was willing to wait to get a mani .\",\n",
       "  'conflict_label': 0},\n",
       " {'id': '5ts_r4K6y103zNXt0k6nEg',\n",
       "  'system': 'denoisesum',\n",
       "  'summary_text': \"i ' ve been here many years and we had a great experience at this place . the food is consistently good and the service is great . sometimes the wait can be a bit long but don ' t go wrong with their food .\",\n",
       "  'conflict_label': 0}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d6b501",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4310c780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eca75fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "198250d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Opening JSON file\n",
    "# this is the original file from the github repo\n",
    "\n",
    "with open('/Users/wenyitay/Documents/moc/data/yelp100_denoisesum.json', 'r') as openfile:\n",
    " \n",
    "    # Reading from json file\n",
    "    data = json.load(openfile)\n",
    "    \n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09fd5a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a22ea6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': 'they offer the best service for the price . the owner is a really nice guy who listens to your needs and will take care of any issues you have . overall a great environment and service you can trust to get your car looking clean and beautiful again .',\n",
       " 'reviews': [\"great wash , friendly staff , can ' t beat the price . get a quality wash for $ 5 in 5 minutes . the higher priced washes are good too . not much more to say than that .\",\n",
       "  \"i went here twice during the week and can say that i won ' t be going elsewhere unless i need a full service experience . they ' ve obviously invested in top notch equipment and as a result the wash does a near perfect job . plus it wasn ' t busy so you can get in and out quickly\",\n",
       "  ' love everything about this place !!!! the ease , the friendliness of the staff , the quality of the wash & vacuums . such a great concept . will definitely come back !!! so happy i found this place . so fast too ! ',\n",
       "  \"what happened to this place ? the owner is a good man , treats people fair , as a matter fact i once drop my wallet called an hour later , he found it and waited 30 minutes past closing for me to get back and pick it up ! however , recently he seem to have hired a bunch of retards who can ' t understand the concept of service . but then again , it ' s $ 10 bucks & location is prime . i ' ll go back there , but only in a pinch !\",\n",
       "  ' great place ! the facility is very clean , quick and convenient ! the staff is also very friendly and helpful ! ',\n",
       "  ' grading with a little bit of a curve for the car wash business but overall experience is always pleasant , generally friendly , and i continue to return . ',\n",
       "  'my go - to quick car wash ! i pass 2 other similarly priced washes to get here and its worth it ! for starters they hand out candy at the register ! the car wash itself does a great job , especially compared to any nearby quick wash places , and of course the vacuums are free . once dropped my wallet here , was still there 2 days later with all its contents . awesome friendly staff ! this should be your go to spot !',\n",
       "  ' pro : brightly lit , open late con : waaay overpriced unless you typically drive in the mud and need lots of car washes for a monthly fee'],\n",
       " 'denoisesum': \"love everything about this place . the staff is friendly and friendly . the food is good , staff is very friendly . i can ' t get enough of any other than that , but i won ' t be disappointed . i will definitely come back .\"}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6cc396",
   "metadata": {},
   "source": [
    "## Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574dcb17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea20d476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbff1596",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
